{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col='Id').sample(frac=1)  # sample(frac=1) -> randomize values\n",
    "target_column = 'SalePrice'\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_abroad_elements(df, columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1244    465000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abroad_sales = utils.get_abroad_values(utils.series_to_float(df[target_column]))\n",
    "df = df.drop(df[abroad_sales].index, axis=0)\n",
    "\n",
    "abroad_sales = utils.get_abroad_values(utils.series_to_float(df[target_column]))\n",
    "df[abroad_sales][target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quantile = df[target_column].quantile(0.99)\n",
    "bottom_quantile = df[target_column].quantile(0.1)\n",
    "df = df[df[target_column] < top_quantile]  # can try for improve model quality\n",
    "df = df[df[target_column] > bottom_quantile]  # can try for improve model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "categorical_values = [\n",
    "    'MSZoning', 'LotShape', 'BldgType', 'HouseStyle', 'MasVnrType', 'ExterQual', 'Foundation',\n",
    "    'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'KitchenQual', 'GarageType',\n",
    "    'GarageFinish', 'YrSold', 'SaleType',\n",
    "]\n",
    "\n",
    "variable_values = [\n",
    "    'MSSubClass', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1',\n",
    "    'BsmtUnfSF', 'TotalBsmtSF', 'GrLivArea', 'BsmtFullBath', 'FullBath', \n",
    "    'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
    "    'GarageCars', 'GarageArea', 'MoSold',\n",
    "]\n",
    "\n",
    "base_df = df[variable_values + categorical_values + [target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим корреляционные элементы\n",
    "\n",
    "delete_columns = {'YrSold'}\n",
    "variable_values = [v for v in variable_values if v not in delete_columns]\n",
    "categorical_values = [v for v in categorical_values if v not in delete_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_area = utils.series_to_float(df['GrLivArea'])\n",
    "is_abroad_area = utils.get_abroad_values(float_area)\n",
    "# print(df.loc[is_abroad_area, 'GrLivArea'])\n",
    "\n",
    "df[is_abroad_area]['GrLivArea']\n",
    "df[is_abroad_area].index\n",
    "# a = df.drop(df[is_abroad_area].index, axis=0)\n",
    "# float_area = series_to_float(a['GrLivArea'])\n",
    "# is_abroad_area = get_abroad_values(float_area)\n",
    "# any(is_abroad_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GrLivArea'].map(float).values.reshape(len(df), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стоит удалить выбросы\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "area_values = np.matrix(df['GrLivArea'].map(float))\n",
    "scaled_area = StandardScaler().fit_transform(df[['GrLivArea']])[:, 0]\n",
    "tresh_hold = 4\n",
    "outer_areas_indexes = ((scaled_area > tresh_hold) | (scaled_area < -1 * tresh_hold))\n",
    "print(df.loc[outer_areas_indexes, 'GrLivArea'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[['GrLivArea']].apply(lambda values: list(map(float, values)))\n",
    "a = df['GrLivArea'].map(float)\n",
    "np.matrix(a)\n",
    "# StandardScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GrLivArea']].apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[variable_values+categorical_values], df[target_column], test_size=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numeric_transformer, variable_values),\n",
    "    ('categorical', categorical_transformer, categorical_values),\n",
    "])\n",
    "preprocessor.fit(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пообучаем и найдем наилучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По заданию должны использовать root-mean-square-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "scoring_rmse = make_scorer(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "print('Train RMSE', rmse(y_train, regressor.predict(X_train)))\n",
    "print('Test RMSE', rmse(y_test, regressor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_params = {\n",
    "    'max_depth': [5, 10, 13, 15], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "tree_grid = GridSearchCV(DecisionTreeRegressor(random_state=17), tree_params, n_jobs=-1, cv=3, verbose=1)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Train RMSE', rmse(y_train, tree_grid.predict(X_train)))\n",
    "print('Test RMSE', rmse(y_test, tree_grid.predict(X_test)))\n",
    "print('Best params', tree_grid.best_params_)\n",
    "print('Best scores', tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randoms_trees_params = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_features': [2, 15, 20],\n",
    "    'max_depth': [10, 15, 20], \n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "random_tree_grid = GridSearchCV(RandomForestRegressor(random_state=17), randoms_trees_params, \n",
    "                                n_jobs=-1, cv=3, verbose=1)\n",
    "random_tree_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Train RMSE', rmse(y_train, random_tree_grid.predict(X_train)))\n",
    "print('Test RMSE', rmse(y_test, random_tree_grid.predict(X_test)))\n",
    "print('Best params', random_tree_grid.best_params_)\n",
    "print('Best scores', random_tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'min_child_weight': [3, 4],\n",
    "    'n_estimators': [100, 150, 500, 1000],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'gamma': [0.1, 0, 1],\n",
    "    'max_depth': [3, 5],\n",
    "}\n",
    "xgb_grid = GridSearchCV(XGBRegressor(random_state=17), xgb_params, early_stopping_rounds=5,\n",
    "                        cv=3, verbose=1, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Train RMSE', rmse(y_train, xgb_grid.predict(X_train)))\n",
    "print('Test RMSE', rmse(y_test, xgb_grid.predict(X_test)))\n",
    "print('Best params', xgb_grid.best_params_)\n",
    "print('Best scores', xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "count_columns = X_train.shape[1]\n",
    "cat_features = list(range(len(variable_values)+1, count_columns))\n",
    "\n",
    "# cat.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False, use_best_model=True)\n",
    "\n",
    "cat_params = {\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate' : [0.01, 0.03, 0.1],\n",
    "}\n",
    "cat = CatBoostRegressor(iterations=700, cat_features=cat_features, random_seed=17)\n",
    "cat_grid = GridSearchCV(cat, cat_params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "cat_grid.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "print('Train RMSE', rmse(y_train, cat_grid.predict(X_train)))\n",
    "# print('Test RMSE', rmse(y_test, cat_grid.predict(X_test)))\n",
    "print('Best params', cat_grid.best_params_)\n",
    "print('Best scores', cat_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "count_columns = X_train.shape[1]\n",
    "\n",
    "keras_seq = Sequential()\n",
    "keras_seq.add(Dense(50, input_dim=count_columns, kernel_initializer='normal', activation='relu'))\n",
    "keras_seq.add(Dropout(0.4))\n",
    "keras_seq.add(Dense(60, kernel_initializer='normal', activation='relu'))\n",
    "keras_seq.add(Dropout(0.4))\n",
    "keras_seq.add(Dense(1, kernel_initializer='normal'))\n",
    "keras_seq.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "keras_seq.fit(X_train, y_train, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "print('Train RMSE', rmse(y_train, keras_seq.predict(X_train)))\n",
    "print('Test RMSE', rmse(y_test, keras_seq.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отдадим kagglе-у ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', index_col='Id')\n",
    "X_test = test_df[variable_values+categorical_values]\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# predicted_test = random_tree_grid.predict(X_test)\n",
    "predicted_test = xgb_grid.predict(X_test)\n",
    "test_df['SalePrice'] = predicted_test\n",
    "test_df.to_csv('answer.csv', columns=['SalePrice'], index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head answer.csv -n 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
