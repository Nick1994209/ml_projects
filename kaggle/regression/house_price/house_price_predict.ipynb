{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col='Id').sample(frac=1)  # sample(frac=1) -> randomize values\n",
    "target_column = 'SalePrice'\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice norm distribution is skewed True\n"
     ]
    }
   ],
   "source": [
    "# на графиках были видны силдьные выбросы у target_column\n",
    "df = utils.delete_abroad_elements(df, target_column)\n",
    "# т.к. SalePrice -> skewed data =>\n",
    "print('SalePrice norm distribution is skewed', not utils.get_skewed_columns(df[[target_column]]).empty)\n",
    "# НЕ ЗАБЫВТЬ произвести np.log1p к SalePrice, для преобразования в нормальное распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'MSZoning', 'LotShape', 'BldgType', 'HouseStyle', 'MasVnrType', 'ExterQual', 'Foundation',\n",
    "    'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'KitchenQual', 'GarageType',\n",
    "    'GarageFinish', 'YrSold', 'SaleType',\n",
    "]\n",
    "\n",
    "numeric_columns = [\n",
    "    'MSSubClass', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1',\n",
    "    'BsmtUnfSF', 'TotalBsmtSF', 'GrLivArea', 'BsmtFullBath', 'FullBath', \n",
    "    'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
    "    'GarageCars', 'GarageArea', 'MoSold',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(\n",
    "    df[numeric_columns+categorical_columns], df[target_column], test_size=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество выбросов: {'LotArea': 9, 'BsmtFinSF1': 1, 'TotalBsmtSF': 3, 'GrLivArea': 3, 'GarageArea': 2}\n"
     ]
    }
   ],
   "source": [
    "# найдем колонки у которых среди значений есть выбросы\n",
    "columns_with_abroad_elements = utils.get_columns_with_count_abroad_elements(X_train_df[numeric_columns])\n",
    "print('количество выбросов: %s' % columns_with_abroad_elements)\n",
    "# удалим выбросы\n",
    "train_df = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "train_df = utils.delete_abroad_elements(train_df, list(columns_with_abroad_elements.keys()))\n",
    "X_train_df, y_train_df = train_df[X_train_df.columns], train_df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YrSold        YrSold          1.000000\n",
       "GarageArea    GarageCars      0.888380\n",
       "GarageYrBlt   YearBuilt       0.844845\n",
       "GrLivArea     TotRmsAbvGrd    0.823060\n",
       "TotRmsAbvGrd  BedroomAbvGr    0.684797\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_columns_correlations(X_train_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим сильно кореллированные с другими признаками элементы\n",
    "delete_columns = {'GarageArea', 'TotRmsAbvGrd', 'YearBuilt', 'TotRmsAbvGrd'}\n",
    "numeric_columns = [v for v in numeric_columns if v not in delete_columns]\n",
    "categorical_columns = [v for v in categorical_columns if v not in delete_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # т.к. пропущенных данных не так много, заполним их медианой\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "skewed_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # т.к. пропущенных данных не так много, заполним их медианой\n",
    "    ('skewer', utils.Log1Transformer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# отдельно будем обрабатывать перекошенные по распределнию данные\n",
    "skewed_columns = list(utils.get_skewed_columns(X_train_df[numeric_columns]))\n",
    "numeric_columns = [c for c in numeric_columns if c not in skewed_columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_columns),\n",
    "    # преобразуем колонки со скошенными распределениями через log1p\n",
    "    ('skewed', skewed_transformer, skewed_columns),\n",
    "    ('categorical', categorical_transformer, categorical_columns),\n",
    "])\n",
    "preprocessor.fit(X_train_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1_transformer = utils.Log1Transformer()\n",
    "X_train, y_train = preprocessor.transform(X_train_df), log1_transformer.transform(y_train_df)\n",
    "X_test, y_test = preprocessor.transform(X_test_df), log1_transformer.transform(y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пообучаем и найдем наилучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По заданию должны использовать root-mean-square-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "scoring_rmse = make_scorer(rmse)\n",
    "\n",
    "\n",
    "def print_rmse_for_model(model):\n",
    "    \"\"\"\n",
    "    Напечатаем rmse к нормированной SalePrice и skewed\n",
    "    \"\"\"\n",
    "    predicted_train = model.predict(X_train)\n",
    "    predicted_test = model.predict(X_test)\n",
    "\n",
    "    print('log Train RMSE', rmse(y_train, predicted_train))\n",
    "    print('log Test RMSE', rmse(y_test, predicted_test))\n",
    "    \n",
    "    print('Train RMSE', rmse(y_train_df, log1_transformer.re_transform(predicted_train)))\n",
    "    print('Train RMSE', rmse(y_test_df, log1_transformer.re_transform(predicted_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log Train RMSE 0.11917153323061246\n",
      "log Test RMSE 0.13720460339785048\n",
      "Train RMSE 20536.704692737254\n",
      "Train RMSE 23231.774285062747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "print_rmse_for_model(regressor)\n",
    "# print('Train RMSE', rmse(y_train, regressor.predict(X_train)))\n",
    "# print('Test RMSE', rmse(y_test, regressor.predict(X_test)))\n",
    "\n",
    "# 73 580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Best scores 0.7680433159636145\n",
      "log Train RMSE 0.14509965622487547\n",
      "log Test RMSE 0.1830318696656999\n",
      "Train RMSE 25177.34933893303\n",
      "Train RMSE 32559.267531563073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_params = {\n",
    "    'max_depth': [5, 10, 13, 15], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "tree_grid = GridSearchCV(DecisionTreeRegressor(random_state=17), tree_params, n_jobs=-1, cv=3, verbose=1)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best params', tree_grid.best_params_)\n",
    "print('Best scores', tree_grid.best_score_)\n",
    "print_rmse_for_model(tree_grid)\n",
    "\n",
    "# 43 562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'max_depth': 20, 'max_features': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "Best scores 0.8640614020748354\n",
      "log Train RMSE 0.05722067630803824\n",
      "log Test RMSE 0.15113928460777587\n",
      "Train RMSE 9840.463809398505\n",
      "Train RMSE 27362.042329363332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randoms_trees_params = {\n",
    "    'n_estimators': [70, 100],\n",
    "    'max_features': [2, 15, 20],\n",
    "    'max_depth': [15, 20], \n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "random_tree_grid = GridSearchCV(RandomForestRegressor(random_state=17), randoms_trees_params, \n",
    "                                n_jobs=-1, cv=3, verbose=1)\n",
    "random_tree_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best params', random_tree_grid.best_params_)\n",
    "print('Best scores', random_tree_grid.best_score_)\n",
    "print_rmse_for_model(random_tree_grid)\n",
    "\n",
    "# RMSE 37 758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:   23.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100}\n",
      "Best scores 0.8763165093301373\n",
      "log Train RMSE 0.09987455435152509\n",
      "log Test RMSE 0.15194150294106867\n",
      "Train RMSE 17119.811200292505\n",
      "Train RMSE 26599.65015832539\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'min_child_weight': [3, 4],\n",
    "    'n_estimators': [50, 100, 300],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'gamma': [0.1, 0, 1],\n",
    "    'max_depth': [3, 5],\n",
    "}\n",
    "xgb_grid = GridSearchCV(XGBRegressor(random_state=17), xgb_params, \n",
    "                        cv=3, verbose=1, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best params', xgb_grid.best_params_)\n",
    "print('Best scores', xgb_grid.best_score_)\n",
    "print_rmse_for_model(xgb_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "# import scipy\n",
    "\n",
    "# count_columns = X_train.shape[1]\n",
    "# cat_features = list(range(len([*numeric_columns, *skewed_columns])+1, count_columns))\n",
    "\n",
    "# # cat.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False, use_best_model=True)\n",
    "\n",
    "# cat_params = {\n",
    "#     'depth': [4, 6, 8],\n",
    "#     'learning_rate' : [0.01, 0.03, 0.1],\n",
    "# }\n",
    "# cat = CatBoostRegressor(iterations=700, cat_features=cat_features, random_seed=17)\n",
    "# cat_grid = GridSearchCV(cat, cat_params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "# cat_X_train = X_train\n",
    "# if isinstance(X_train, scipy.sparse.csr.csr_matrix):\n",
    "#     cat_X_train = X_train.toarray()\n",
    "# cat_grid.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "# print('Best params', cat_grid.best_params_)\n",
    "# print('Best scores', cat_grid.best_score_)\n",
    "# print_rmse_for_model(cat_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log Train RMSE 0.16212175317574276\n",
      "log Test RMSE 0.19765094662421706\n",
      "Train RMSE 29200.942279243238\n",
      "Train RMSE 36865.6672981417\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "count_columns = X_train.shape[1]\n",
    "\n",
    "keras_seq = Sequential()\n",
    "keras_seq.add(Dense(100, input_dim=count_columns, activation='relu'))\n",
    "keras_seq.add(Dropout(0.4))\n",
    "keras_seq.add(Dense(60, activation='relu'))\n",
    "keras_seq.add(Dropout(0.4))\n",
    "keras_seq.add(Dense(1))\n",
    "keras_seq.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "keras_seq.fit(X_train, y_train, epochs=100, batch_size=3, verbose=0)\n",
    "\n",
    "print_rmse_for_model(keras_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отдадим kagglе-у ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', index_col='Id')\n",
    "X_test = test_df[numeric_columns+skewed_columns+categorical_columns]\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "def write_answer(model, file_name):\n",
    "    predicted_test = model.predict(X_test)\n",
    "    test_df['SalePrice'] = log1_transformer.re_transform(predicted_test)\n",
    "    test_df.to_csv(file_name, columns=['SalePrice'], index_label='Id')\n",
    "    \n",
    "write_answer(xgb_grid, 'xgb_answer.csv')\n",
    "write_answer(random_tree_grid, 'random_tree_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,SalePrice\r\n",
      "1461,111703.375\r\n",
      "1462,168715.52\r\n",
      "1463,175607.31\r\n",
      "1464,188060.12\r\n"
     ]
    }
   ],
   "source": [
    "!head xgb_answer.csv -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,SalePrice\r\n",
      "1461,118856.97352568615\r\n",
      "1462,158700.61000367405\r\n",
      "1463,176500.50545566785\r\n",
      "1464,188609.32694291568\r\n"
     ]
    }
   ],
   "source": [
    "!head random_tree_answer.csv -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'answer.csv' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head answer.csv -n 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
