{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col='Id').sample(frac=1)  # sample(frac=1) -> randomize values\n",
    "target_column = 'SalePrice'\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SalePrice norm distribution is skewed True\n"
     ]
    }
   ],
   "source": [
    "# на графиках были видны силдьные выбросы у target_column\n",
    "df = utils.delete_abroad_elements(df, target_column)\n",
    "# т.к. SalePrice -> skewed data =>\n",
    "print('SalePrice norm distribution is skewed', not utils.get_skewed_columns(df[[target_column]]).empty)\n",
    "# НЕ ЗАБЫВТЬ произвести np.log1p к SalePrice, для преобразования в нормальное распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'MSZoning', 'LotShape', 'BldgType', 'HouseStyle', 'MasVnrType', 'ExterQual', 'Foundation',\n",
    "    'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'KitchenQual', 'GarageType',\n",
    "    'GarageFinish', 'YrSold', 'SaleType',\n",
    "]\n",
    "\n",
    "numeric_columns = [\n",
    "    'MSSubClass', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1',\n",
    "    'BsmtUnfSF', 'TotalBsmtSF', 'GrLivArea', 'BsmtFullBath', 'FullBath', \n",
    "    'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
    "    'GarageCars', 'GarageArea', 'MoSold',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(\n",
    "    df[numeric_columns+categorical_columns], df[target_column], test_size=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "количество выбросов: {'LotArea': 8, 'BsmtFinSF1': 2, 'BsmtUnfSF': 1, 'TotalBsmtSF': 3, 'GrLivArea': 3, 'BsmtFullBath': 1, 'BedroomAbvGr': 1, 'TotRmsAbvGrd': 1, 'GarageArea': 3}\n"
     ]
    }
   ],
   "source": [
    "# найдем колонки у которых среди значений есть выбросы\n",
    "columns_with_abroad_elements = utils.get_columns_with_count_abroad_elements(X_train_df[numeric_columns])\n",
    "print('количество выбросов: %s' % columns_with_abroad_elements)\n",
    "# удалим выбросы\n",
    "train_df = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "train_df = utils.delete_abroad_elements(train_df, list(columns_with_abroad_elements.keys()))\n",
    "X_train_df, y_train_df = train_df[X_train_df.columns], train_df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # удалим корреляционные элементы\n",
    "\n",
    "# delete_columns = {'YrSold'}\n",
    "# variable_values = [v for v in variable_values if v not in delete_columns]\n",
    "# categorical_values = [v for v in categorical_values if v not in delete_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # т.к. пропущенных данных не так много, заполним их медианой\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "skewed_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # т.к. пропущенных данных не так много, заполним их медианой\n",
    "    ('skewer', utils.Log1Transformer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# отдельно будем обрабатывать перекошенные по распределнию данные\n",
    "skewed_columns = list(utils.get_skewed_columns(X_train_df[numeric_columns]))\n",
    "numeric_columns = [c for c in numeric_columns if c not in skewed_columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numeric_transformer, skewed_columns),\n",
    "    ('categorical', categorical_transformer, categorical_columns),\n",
    "    # преобразуем колонки со скошенными распределениями через log1p\n",
    "    ('skewed', skewed_transformer, skewed_columns),\n",
    "])\n",
    "preprocessor.fit(X_train_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1_transformer = utils.Log1Transformer()\n",
    "X_train, y_train = preprocessor.transform(X_train_df), log1_transformer.transform(y_train_df)\n",
    "X_test, y_test = preprocessor.transform(X_test_df), log1_transformer.transform(y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пообучаем и найдем наилучшую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По заданию должны использовать root-mean-square-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "scoring_rmse = make_scorer(rmse)\n",
    "\n",
    "\n",
    "def print_rmse_for_model(model):\n",
    "    \"\"\"\n",
    "    Напечатаем rmse к нормированной SalePrice и skewed\n",
    "    \"\"\"\n",
    "    predicted_train = model.predict(X_train)\n",
    "    predicted_test = model.predict(X_test)\n",
    "\n",
    "    print('log Train RMSE', rmse(y_train, predicted_train))\n",
    "    print('log Test RMSE', rmse(y_test, predicted_test))\n",
    "    \n",
    "    print('Train RMSE', rmse(y_train_df, log1_transformer.re_transform(predicted_train)))\n",
    "    print('Train RMSE', rmse(y_test_df, log1_transformer.re_transform(predicted_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log Train RMSE 0.1687248517733512\n",
      "log Test RMSE 0.1779041857907157\n",
      "Train RMSE 30982.480926573742\n",
      "Train RMSE 32525.840349995247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "print_rmse_for_model(regressor)\n",
    "# print('Train RMSE', rmse(y_train, regressor.predict(X_train)))\n",
    "# print('Test RMSE', rmse(y_test, regressor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log Train RMSE 0.14389909226125952\n",
      "log Test RMSE 0.2600561866040972\n",
      "Train RMSE 25256.635523703317\n",
      "Train RMSE 45626.74636808797\n",
      "Best params {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Best scores 0.6142093804786899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_params = {\n",
    "    'max_depth': [5, 10, 13, 15], \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "tree_grid = GridSearchCV(DecisionTreeRegressor(random_state=17), tree_params, n_jobs=-1, cv=3, verbose=1)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "print_rmse_for_model(tree_grid)\n",
    "print('Best params', tree_grid.best_params_)\n",
    "print('Best scores', tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'max_depth': 15, 'max_features': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best scores 0.76964185824589\n",
      "log Train RMSE 0.07463230529033126\n",
      "log Test RMSE 0.1879651255358773\n",
      "Train RMSE 13997.036604489698\n",
      "Train RMSE 35391.53975520931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randoms_trees_params = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'max_features': [2, 15, 20],\n",
    "    'max_depth': [10, 15, 20], \n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "random_tree_grid = GridSearchCV(RandomForestRegressor(random_state=17), randoms_trees_params, \n",
    "                                n_jobs=-1, cv=3, verbose=1)\n",
    "random_tree_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best params', random_tree_grid.best_params_)\n",
    "print('Best scores', random_tree_grid.best_score_)\n",
    "print_rmse_for_model(random_tree_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   28.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 100}\n",
      "Best scores 0.7748619707226465\n",
      "log Train RMSE 0.12050104861728715\n",
      "log Test RMSE 0.1940652949180911\n",
      "Train RMSE 22127.08295987925\n",
      "Train RMSE 35092.881512650354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed:   43.0s finished\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'min_child_weight': [3, 4],\n",
    "    'n_estimators': [50, 100, 300],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'gamma': [0.1, 0, 1],\n",
    "    'max_depth': [3, 5],\n",
    "}\n",
    "xgb_grid = GridSearchCV(XGBRegressor(random_state=17), xgb_params, \n",
    "                        cv=3, verbose=1, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best params', xgb_grid.best_params_)\n",
    "print('Best scores', xgb_grid.best_score_)\n",
    "print_rmse_for_model(xgb_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "# count_columns = X_train.shape[1]\n",
    "# cat_features = list(range(len([*numeric_columns, *skewed_columns])+1, count_columns))\n",
    "\n",
    "# # cat.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False, use_best_model=True)\n",
    "\n",
    "# cat_params = {\n",
    "#     'depth': [4, 6, 8],\n",
    "#     'learning_rate' : [0.01, 0.03, 0.1],\n",
    "# }\n",
    "# cat = CatBoostRegressor(iterations=700, cat_features=cat_features, random_seed=17)\n",
    "# cat_grid = GridSearchCV(cat, cat_params, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "# print(type(X_train.toarray()), type(y_train))\n",
    "# # X_train is scipy.sparse.csr.csr_matrix\n",
    "# cat_grid.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "# print('Best params', cat_grid.best_params_)\n",
    "# print('Best scores', cat_grid.best_score_)\n",
    "# print_rmse_for_model(cat_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "\n",
    "# count_columns = X_train.shape[1]\n",
    "\n",
    "# keras_seq = Sequential()\n",
    "# keras_seq.add(Dense(100, input_dim=count_columns, activation='relu'))\n",
    "# keras_seq.add(Dropout(0.4))\n",
    "# keras_seq.add(Dense(60, activation='relu'))\n",
    "# keras_seq.add(Dropout(0.4))\n",
    "# keras_seq.add(Dense(1))\n",
    "# keras_seq.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# keras_seq.fit(X_train, y_train, epochs=100, batch_size=3, verbose=0)\n",
    "\n",
    "# print_rmse_for_model(keras_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отдадим kagglе-у ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', index_col='Id')\n",
    "X_test = test_df[numeric_columns+skewed_columns+categorical_columns]\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# BAD TODODOODODOD\n",
    "\n",
    "def write_answer(model, file_name):\n",
    "    predicted_test = model.predict(X_test)\n",
    "    test_df['SalePrice'] = log1_transformer.re_transform(predicted_test)\n",
    "    test_df.to_csv(file_name, columns=['SalePrice'], index_label='Id')\n",
    "    \n",
    "# write_answer(keras_seq, 'keras_answer.csv')\n",
    "write_answer(xgb_grid, 'xgb_answer.csv')\n",
    "write_answer(random_tree_grid, 'random_tree_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,SalePrice\r\n",
      "1461,22655.904\r\n",
      "1462,25319.768\r\n",
      "1463,29063.393\r\n",
      "1464,31260.012\r\n"
     ]
    }
   ],
   "source": [
    "!head keras_answer.csv -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,SalePrice\r\n",
      "1461,123126.6\r\n",
      "1462,159749.08\r\n",
      "1463,184490.95\r\n",
      "1464,186443.83\r\n"
     ]
    }
   ],
   "source": [
    "!head xgb_answer.csv -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,SalePrice\r\n",
      "1461,135041.1955175371\r\n",
      "1462,178075.66364487834\r\n",
      "1463,190699.6935160959\r\n",
      "1464,192987.44268104836\r\n"
     ]
    }
   ],
   "source": [
    "!head random_tree_answer.csv -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,SalePrice\r\n",
      "1461,127339.375\r\n",
      "1462,164522.94\r\n",
      "1463,184828.14\r\n",
      "1464,182903.52\r\n"
     ]
    }
   ],
   "source": [
    "!head answer.csv -n 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
